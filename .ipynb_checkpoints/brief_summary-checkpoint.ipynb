{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f22043-e732-4914-b4d3-b71e34d4c7b3",
   "metadata": {},
   "source": [
    "## 베이즈 기초\n",
    "\n",
    "* $\\mu$ : Gaussian Distribution의 평균\n",
    "* $\\Sigma$ : Gaussian Distribution의 공분산\n",
    "* $\\theta$ : 학습 가능한 파라미터 (Gaussian Distribution의 경우 $\\mu, \\Sigma$\n",
    "* $Z$ : 잠재 변수를 전부 합한 잠재변수 층\n",
    "* $X$ : 전체 데이터 (Random Variable)\n",
    "* $x \\sim P(X)$ : pdf $P(X)$으로부터 추출한 샘플 $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b5c60-a68b-48a4-bf8c-45992891eb0b",
   "metadata": {},
   "source": [
    "예시를 들어,<br>\n",
    "$X$ 가 {`강아지`, `고양이`} 둘 중 하나를 담은 이미지의 픽셀 벡터이고,<br>\n",
    "$Z$ 가 강아지면 0, 고양이면 1을 출력하는 label {`0`, `1`} 이라면,\n",
    "\n",
    "$\\large p(Z|X) = \\LARGE \\frac{p(X|Z)p(Z)}{p(X)}$\n",
    "\n",
    "* `Prior` : 우리가 알기를 원하는 $Z$에 대해 알고 있는 정보. $\\large p(Z)$\n",
    "> 데이터셋에서 고양이 사진이 전체의 1/3이라면 $p(Z=1) = \\LARGE \\frac{1}{3}$<br>\n",
    "> 강아지 사진이 나머지 2/3이므로 $p(Z=0) = \\LARGE \\frac{2}{3}$\n",
    "\n",
    "* `Posterior` : 우리가 가진 데이터 $X$을 가지고 구하고 싶은 결과 $\\large p(z|x)$\n",
    "> 이미지 $X$이 주어진 경우 고양이 $1$로 출력할 확률\n",
    "  \n",
    "* `Likelihood` : $Z$가 주어진 경우 이미지 $X$가 {`강아지`, `고양이`}에 있을지 가능성  $\\large p(x|z)$\n",
    "> $x \\sim P(X|Z)$ 을 통해 x을 뽑을 수 있다면 고양이, 강아지 이미지를 생성 가능!<br> ==> Bayesian이 생성모델에 사용되는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacf055-836f-4ab3-a28f-61886dc2cfaf",
   "metadata": {},
   "source": [
    "## Variational Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cffb7-80e5-4af0-89ea-b21ee1e05d80",
   "metadata": {},
   "source": [
    "이전 예제를 확장해서, Neural Network에서 가지고 있는 $X$를 가지고 우리가 알기를 원하는 $Z$를 구하기 위해서는 $Z$을 구성하는 파라미터의 분포인 `Posterior` $\\large p(Z|X)$을 구해야 한다.\n",
    "\n",
    "하지만, 기존 posterior 식\n",
    "\n",
    "$$\\large \\text{posterior : } P(z|x) = \\frac{p(x|z)p(z)}{p(x)} = \\frac{p(x|z)P(z)}{\\sum\\limits_{z}P(x|z)P(z)dz}$$\n",
    "\n",
    "으로는 $p(z|x)$을 구할 수 없다.\n",
    "\n",
    "그 이유는 Posterior의 분모인 원래 데이터의 분포 $p(x)$을 구할 수 없기 때문이다 (Only God knows True Data Distribution)\n",
    "\n",
    "why? because $\\large p(x)$은 $x$의 하위에 있는 latent variable $z_1, ..., z_n$의 joint distribution $\\large p(x, z)$을 전부 더해서 구할 수 있는데, Neural Network의 경우 최소 수백만개가 넘는 파라미터가 있기 때문! <br> ==> 수백만번이 넘는 적분을 수행해야함 (we call this phenomenon \"intractable\" -> 계산 불가능)\n",
    "\n",
    "따라서 posterior를 구하기 위해서는 ${\\sum\\limits_{z}P(x|z)P(z)dz}$을 우회해서 계산하는 방법을 찾아야 하고 그 방법으로 소개할 개념이 바로\n",
    "\n",
    "* ELBO method (Evidence Lower Bound)\n",
    "* KL Divergence (Kullback–Leibler divergence)\n",
    "* Mean-Field Variational Inference\n",
    "\n",
    "이다. \n",
    "\n",
    "요약: 적분 불가능한 $p(z|x)$, $p(x)$을 구하기 위해 위 세가지 방식을 사용해 우회한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d633e1-1900-4121-9648-0be98d923abc",
   "metadata": {},
   "source": [
    "## KL Divergence\n",
    "\n",
    "앞서 소개했듯이 $p(z|x)$은 intractable (계산 불가능)하기 때문에, 우리는 $p(z|x)$과 Gaussian Distribution의 분포들인 $Q$ 중에서 $p(z|x)$와 가장 가까운 가우시안 분포 $q(z)$로 근사하여 계산한다.<br> ==> 두 분포가 다른 정도를 나타내는 `KL Divergence`를 최소화!\n",
    "\n",
    "[KL Divergence와 Entropy 설명 외부 링크](https://icim.nims.re.kr/post/easyMath/550)\n",
    "\n",
    "<img src = './img/week0_1.png' style = \"width : 700px;\">\n",
    "\n",
    "$\\large \\because$ $q$는 $p(z|x)$와 유사한 아무 분포를 사용해도 되지만 가우시안 분포 $q$를 사용하는 이유는 바로 가우시안 분포는 식에 변형 (marginalize, conditional)을 주어도 계속 가우시안의 형질을 유지하기 때문\n",
    "\n",
    "왼쪽의 `그림 1`를 설명하자면, 임의의 가우시안 분포의 집합인 $Q$에서 $q(z)$를 임의로 설정한 다음에, 해당 $q(z)$을 optimize해나가는 과정을 통해 우리가 알고 싶은 식인 $p(z|x)$간의 거리가 최소가 되는 분포 $q(z)$가 될때까지 업데이트하면 `그림2`의 가우시안 분포로 근사가 가능하다!\n",
    "\n",
    "이 때 `그림 1`의 $q(z)$와 $p(z|x)$간 최소거리가 바로 **KL Divergence** $\\large KL(q(z)|p(z|x))$ 이다.\n",
    "\n",
    "거리(유사도)는 항상 0 이상의 값을 가지기 때문에 KL Divergence 값은 항상 0을 넘는다.\n",
    "\n",
    "$\\large KL(q(z)|p(z|x))$을 전개해 $p(z|x)$와 가장 유사도가 높은 $q(z)$을 구하고자 한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef32e0-bef9-4171-ada8-de54288c8bfd",
   "metadata": {},
   "source": [
    "<img src = './img/week0_2.png' style = \"width : 550px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7013d-5623-48d7-be57-c140b4c7c90e",
   "metadata": {},
   "source": [
    "하지만, 결국 $p(x)$라는 계산 불가능한 식이 남아있기 때문에 $q(z)$을 구할 수 없다.<br>\n",
    "이 문제를 해결하기 위해 **Evidence Lower Bound (ELBO)** 를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9876b-ab8e-4bda-9f57-5c80e277fa14",
   "metadata": {},
   "source": [
    "## Evidence Lower Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c35703-366e-4d87-a879-37eb23051c28",
   "metadata": {},
   "source": [
    "KL Divergence 식을 통해\n",
    "\n",
    "$\\large KL(q(z)|p(z|x)) = \\mathbb{E}_q[log(q(z) - logp(x,z)] + logp(x)$\n",
    "\n",
    "을 얻었지만, 아직 $KL(q(z)|p(z|x))$와 $logp(x)$을 계산할 수 없기 때문에 원하는 값을 구할 수 없다.\n",
    "\n",
    "우선 계산 가능한 값을 왼쪽 식으로 두고 계산이 불가능한 값을 오른쪽 식으로 분리하면\n",
    "\n",
    "$\\large \\mathbb{E}_q[logp(x,z) - log(q(z)] = logp(x) - KL(q(z)|p(z|x))$\n",
    "\n",
    "이 되는데, 여기서 꼼수를 사용해서\n",
    "\n",
    "계산이 가능한 식 $\\large \\mathbb{E}_q[logp(x,z) - log(q(z)]$ 을 최대화하면,\n",
    "\n",
    "우리가 최대화하기를 원하는 `Evidence` $\\large logp(x)$가 maximize되고\n",
    "\n",
    "우리가 최소화하기를 원하는 `KL Divergence` $\\large KL(q(z)|p(z|x))$가 minimize되니까\n",
    "\n",
    "계산할 수 없는 식을 계산이 가능한 왼쪽 식을 maximize하는 걸로 approximate 할 수 있지 않을까..? 하는 생각을 할 수 있는데,\n",
    "\n",
    "실제로 이렇게 계산 가능한 식을 최대화해 evidence인 $\\large logp(x)$에 lower bound가 형성되는 알고리즘을<br> `ELBO method`으로 부른다.\n",
    "\n",
    "`ELBO method`을 통해 왼쪽 식을 푼다면\n",
    "\n",
    "<img src = './img/week0_3.png' style = \"width : 550px;\">\n",
    "\n",
    "이 나오고, 이 계산가능한 마지막 식\n",
    "\n",
    "$\\large \\mathbb{E}_q[logp(x|z)] - KL(q(z)|p(z))$ 을 최대화함으로서\n",
    "\n",
    "우측의 $q(z)$와 $p(z|x)$ 분포 간 차이를 나타내는 $\\large KL(q(z)|p(z|x))$ 가 0으로 수렴하게 되고,\n",
    "\n",
    "결국에는 Evidence $\\large logp(x)$의 값이 나오게 되므로 $\\large p(x)$의 값을 구할 수 있게 되고,\n",
    "\n",
    "$p(x)$를 못 구해서 계산하지 못한 Posterior\n",
    "\n",
    "$$\\large \\text{posterior : } P(z|x) = \\frac{p(x|z)p(z)}{p(x)}$$\n",
    "\n",
    "식을 구할 수 있게 된다. 야호!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3034095-e35d-4047-b567-7e17a6b44193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
