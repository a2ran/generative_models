{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb9dcc3-e2d4-44ed-8c88-350c4ea35576",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model to EM\n",
    "\n",
    "* `Prior` : 우리가 알기를 원하는 $Z$에 대해 알고 있는 정보. $\\large p(Z)$\n",
    "* `Posterior` : 우리가 가진 데이터 $X$을 가지고 구하고 싶은 확률분포 $\\large p(z|x)$\n",
    "* `Likelihood` : $Z$가 주어진 경우 입력값 $X$의 확률분포  $\\large p(x|z)$\n",
    "\n",
    "`Univariate Gaussian Distribution`\n",
    "\n",
    "$$\\large p(x| \\mu, \\sigma^2) = N(x| \\mu, \\sigma^2) = \\LARGE \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\large exp \\LARGE (-\\frac{(x - \\mu)^2}{2\\sigma^2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba87498-e641-4333-a3e6-1d4a0ce98c29",
   "metadata": {},
   "source": [
    "<img src = './img/week0_4.png' style = \"width : 550px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11b8a1-c41c-4743-ae3d-3ee67ac8a45c",
   "metadata": {},
   "source": [
    "2차원의 평면에 두 개의 가우시안 분포 `A`와 `B`가 있다고 가정하자.\n",
    "\n",
    "각 가우시안 분포는 $\\large N(x | \\mu_A, \\Sigma_A)$, $\\large N(x | \\mu_B, \\Sigma_B)$ 이고,\n",
    "\n",
    "분석하기를 원하는 새로운 데이터 `X`가 주어졌을 때,\n",
    "\n",
    "각각의 분포 $A$와 $B$에서 나온 데이터일 확률을 $\\pi$라고 한다.\n",
    "\n",
    "$\\large \\mathbb{P}(A) = \\pi_A$, $\\large \\mathbb{P}(B) = \\pi_B$<br>\n",
    "($\\mathbb{P}(z) = \\pi = [\\pi_1 , \\cdot\\cdot\\cdot, \\pi_K]^T, 0 \\le \\pi_k \\le 1, \\sum\\limits_{k=1}^K \\pi_k = 1$)\n",
    "\n",
    "두 가지 가우시안 분포 $A$와 $B$가 있을 때 새로운 데이터 $X$을 관측할 확률은, 각각의 가우시안 분포에 나올 확률을 곱해준 값을 합하면 된다.\n",
    "\n",
    "$\\large \\mathbb{P}(x) = \\pi_A N(x | \\mu_A, \\Sigma_A) + \\pi_B N(x | \\mu_B, \\Sigma_B) = \\sum\\limits_{k=1}^K \\pi_k N(x | \\mu_k, \\Sigma_k)$\n",
    "\n",
    "전체 데이터셋에 대한 가우시안 분포 :\n",
    "\n",
    "$\\large \\therefore \\mathbb{P}(X| \\pi, \\mu, \\Sigma) = \\prod\\limits_{n=1}^N[\\sum\\limits_{k=1}^K \\pi_k N(x | \\mu_k, \\Sigma_k)]$\n",
    "\n",
    "따라서, $p(X|\\pi, \\mu, \\Sigma)$을 구하기 위해서는 파라미터인 $\\pi, \\mu, \\Sigma$를 최적화하면 되지만,<br> 실제 상황에서는 $X$가 두개의 가우시안 분포가 아닌 수백개 ~ 수백만개의 가우시언 분포에서 도출되므로 문제가 발생한다.<br> (like in the case of variational inference)\n",
    "\n",
    "우선 $\\pi_k$의 개수가 엄청 많아질 수도 있으므로 $z_{nk}$라는 할당자를 새로 정의한다.\n",
    "\n",
    "$\\large z_{nk} = \\LARGE\n",
    "\\begin{cases}\n",
    "    1, & \\text{if } x_n \\text{in class } k\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}$\n",
    "\n",
    "우리는 $x_n$이 주어졌을 때 각 클래스 $k$ 에서 올 확률을 구하기 위해<br> 해당 가우시안 분포의 responsibility (책임) $\\gamma(z_{nk})$을 정의한다.\n",
    "\n",
    "$\\large \\gamma(z_{nk}) = \\mathbb{P}(z_{nk}=1|x_n) = \\LARGE \\frac{\\pi_k N(x_n | \\mu_k, \\Sigma_k)}{\\sum\\limits_{j=1}^k \\pi_j N(x | \\mu_j, \\Sigma_j)} = \\frac{\\mathbb{P}(z_k=1) \\mathbb{P}(x_n | z_{nk}=1)}{\\sum\\limits_{j=1}^k \\mathbb{P}(z_{nj}=1) \\mathbb{P}(x_n | z_{nj}=1)}$\n",
    "\n",
    "$\\large \\therefore N_k = \\sum\\limits_{n=1}^N \\gamma(z_{nk})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6813ec-bfe7-40e7-8368-f1f8793d1802",
   "metadata": {},
   "source": [
    "수식은 추후에 증명할 거지만,\n",
    "\n",
    "ELBO, KL Divergence 등을 통해 파라미터 $\\pi, \\mu, \\Sigma$에 대해 다음과 같은 식을 도출할 수 있다.\n",
    "\n",
    "$$\\LARGE \\mu_k = \\frac{1}{N_k} \\large \\sum\\limits_{n=1}^N \\gamma(z_{nk})x_n $$\n",
    "$$\\LARGE \\Sigma_k = \\frac{1}{N_k} \\large \\sum\\limits_{n=1}^N \\gamma(z_{nk})(x_n - \\mu_k)(x_n - \\mu_k)^T $$\n",
    "$$\\LARGE \\pi_k = \\frac{N_k}{N}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c974ba-e20a-4ff7-84b7-1a43df739660",
   "metadata": {},
   "source": [
    "결국,\n",
    "\n",
    "* $\\mu_k, \\Sigma_k, \\pi_k$를 계산하는 데에 있어 $\\gamma(z_{nk})$ 가 필요하고,\n",
    "* 반대로 $\\gamma(z_{nk})$를 계산하는 데에 있어 $\\mu_k, \\Sigma_k, \\pi_k$가 필요하므로,\n",
    "\n",
    "파라미터 $\\mu_k, \\Sigma_k, \\pi_k$와 최종 결과 $N_k$를 구할 수 있는 $\\gamma(z_{nk})$을 번갈아서 최적화해<br> $\\gamma(z_{nk})$을 최대화하는 $\\mu_k, \\Sigma_k, \\pi_k$ 을 구하는 방식이 바로<br> `Expectation - Maximization (EM) Algorithm` 이다!\n",
    "\n",
    "### EM Algorithm Step\n",
    "\n",
    "1. $\\mu_k, \\Sigma_k, \\pi_k$ 파라미터 초기 설정\n",
    "2. $\\mu_k, \\Sigma_k, \\pi_k$ 파라미터로부터 $\\gamma(z_{nk})$을 계산 (Expectation)\n",
    "3. 해당 $\\gamma(z_{nk})$을 최대화하는 $\\mu_k, \\Sigma_k, \\pi_k$으로 파라미터 변경 (Maximization\n",
    "4. 다시 2번, 3번 과정 반복\n",
    "5. 정의한 loss function이 threshold 미만으로 가거나, 일정 epoch를 지나면 학습 종료!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8d3a9-6029-4774-b937-12841dd047d2",
   "metadata": {},
   "source": [
    "<img src = './img/week0_5.png' style = \"width : 700px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebf5cd-abef-4519-a9fe-ba7d4e48c42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
