<img src="https://wikidocs.net/images/page/229463/continuous1.png" width="50%">

각기 다른 사람들의 얼굴 사진을 담은 데이터셋 $D$가 있다고 하면, 얼굴 이미지 $X$는 RGB 픽셀 값들 $x_i$로 이루어져 있지만, 명시적으로 적혀져 있지 않는 여러 특징들이 존재합니다.

> 성별, 나이, 머리카락의 색깔, 동공의 색깔, 머리카락의 유무 등등...

하지만, 해당 특징들은 RGB 픽셀 값들처럼 명시적으로 적혀져 있는 것이 아니라, 저희가 이미지로부터 추론해야 하는 특징들입니다. 해당 성질을 지닌 특징들을 저희는 **잠재 변수 (latent variables) $z$**으로 명칭합니다.

잠재 변수 모형 (Latent Variable Models)은 해당 잠재 변수 $z$를 비지도 학습으로 학습해 해당 특징들을 반영한 생성 모델 알고리즘입니다. 이 작업을 수행하기 위해서는, 기존 $p_{model}(x)$을 구하는 목표를, 데이터 $x$와 함께  $z$가 나타날 확률 분포인 joint distribution $p(x, z)$을 학습해야 합니다.

## Latent Variable Models

<img src="https://wikidocs.net/images/page/229463/continuous2.png" width="15%">

가장 기본적인 잠재변수 모형은 베이즈 정리에 따라 다음과 같이 정의할 수 있습니다.

$$p(x,z) = p(x|z)p(z) $$

저희는 기존 $p(x)$에서 변수 $x$와 더불어 잠재 변수 $z$에 대한 joint distribution $p(x,z)$으로 나타내, 생성 모델이 $z$와 $p(x,z)$을 학습하게 설정합니다.

## 잠재 변수 학습의 어려움

<img src="https://wikidocs.net/images/page/229463/continuous3.png" width="80%">

각기 다른 사람들의 얼굴 사진을 담은 데이터셋 $D$가 있다고 하면,  관측 변수 $x$는 이미지 데이터이고, 해당 이미지 데이터의 특징인 Gender, Eye color, Hair color, Ethnicity...은 잠재 변수 $z_i, \cdot\cdot\cdot z_k$입니다. 만일 이미지 데이터 $x$을 받아 첫번째 잠재 변수 "성별" $z_1$을 나타내고 싶다면, **posterior** $p(z_1|x)$에 대한 생성 모델을 구축해 학습함으로서 해결할 수 있습니다.

하지만, $p(x)$을 수식으로 계산할 수 있었던 autoregressive 모델과는 달리, $z$와 같은 잠재 변수들은 $p(x,z) = p(x|z)p(z)$에 따라 $p(x|z)$을 구해야 하고, 저차원의 잠재변수 $z$ (if 성별 => $z_1 \in [0,1]$)에서 고차원의 이미지 데이터 $x$을 매핑하는 조건부확률 $p(x|z)$을 계산하기는 거의 불가능에 가깝습니다(Intractable). 따라서, 저희는 해당 작업을 수행하기 위해 거의 필수적으로 아주 복잡한 심층 신경망 구조를 구축해야 합니다.

또한, 이미지 $x$은 위 이미지에서 나타난 대표적인 잠재변수 $z$외에도 여러가지 다른 잠재변수들이 있고, 해당 잠재변수간의 관계를 매핑하는 작업도 사전에 정의하기 불가능한 경우가 빈번하게 존재합니다. 따라서, 저희는 해당 문제점들을 전부 해결할 수 있는 심층 신경망 구조를 수립해야 합니다.

## Continuous Latent Variable Representations

<img src="https://wikidocs.net/images/page/229463/continuous4.png" width="60%">

이 문제점들을 해결하기 위해, 저희는 각각의 잠재 변수 $z$에 대해 따로따로 (discrete)하게 학습하는 것이 아니라, 연속적인 벡터 $z$을 설정해 $z$에서 $x$으로 매핑하는 심층 신경망 구조를 학습하고자 합니다.

해당 신경망 구조를 사용하면, $z$의 어느 특정한 부분이 저희가 알기를 원하는 잠재 변수 (성별, 머리카락 유무...)인지 직접적으로 알 수 는 없지만, 매핑한 결과를 비지도 학습을 통해 클러스터링해, $z$을 기준으로 비슷한 이미지 $x$을 묶을 수 있습니다. 이를 통해 저희는 특정 잠재변수에 따라 완벽하기 이미지를 구분할 수는 없지만, 특징에 따라 묶여있는 유사한 이미지들 (동일한 나이, 동일한 성별...)을 묶은 클러스터를 분석해 해당 클러스터가 어떠한 잠재변수 $z$을 나타내는지 유추할 수 있습니다.

따라서, 잠재 변수의 벡터 $z$에서 $x$을 매핑하는 $p(x|z)$을 심층 신경망 구조가 학습하게 한 이후 해당 결과를 유사한 결과끼리 클러스터링하여 저희가 구하고자 하는 잠재 변수의 클러스터에 해당하는 $p(x,z)$을 근사할 수 있습니다. 이를 통해 각기 다른 잠재 변수들의 확률 군포를 구할 수 있게 되고, 해당 이미지로부터 각기 다른 특징의 이미지를 생성 할 수 있습니다. **(Representation Learning!!)**