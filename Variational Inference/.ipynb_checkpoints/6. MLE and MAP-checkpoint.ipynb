{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b234bce3-689e-4384-b976-bbcf0be1316e",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "Consider a regressive dataset :\n",
    "\n",
    "$$\\large D = \\{(x_1,t_1), (x_2,t_2), (x_3,t_3), \\cdot\\cdot\\cdot , (x_N, t_N) \\}$$\n",
    "\n",
    "* $\\large x_i$ : input\n",
    "* $\\large t_i$ : actual data (label)\n",
    "* $\\large y_i$ : output\n",
    "\n",
    "To predict a random variable $t_i$ given input data $x_i$ and **parameter** $w$,<br>\n",
    "We may use a conditional probability $x$ given $w$.\n",
    "\n",
    "$$\\large t = y(x|w)$$\n",
    "\n",
    "* $\\large w$ : parameter ($y = a_1x_1 + a_2x_2 + b$, $w = a_1, a_2$)\n",
    "\n",
    "So we may assume that the label $t$ follows the **gaussian distribution** of mean $y(x|w)$ and variance $\\sigma$.<br>\n",
    "$\\sigma$ is a constant variable.\n",
    "\n",
    "$$\\large t \\sim N(y(x|w), \\sigma^2)$$\n",
    "$$\\large p(t|x,w,\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(t-y(x|w))^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc372f4-79e0-4b5a-885c-992ccfce2463",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "* $p(t|x)$ : probability of a likelihood of $y$ and $t$ when given $x$\n",
    "* $p(D|w)$ : The total sum of a probability of likelihoods from 1 to $N$ when given $W$.\n",
    "\n",
    "$$\\large p(D|w) = \\prod\\limits_{i=1}^n p(t_i|x_i) = \\prod\\limits_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(t_i-y(x_i|w))^2}{2\\sigma^2}}$$\n",
    "\n",
    "The best model maximizes a total sum of probability of likelihoods $p(D|w)$, and we must find $w$ that maximizes $p(D|w)$. $\\rightarrow$ Maximum Likelihood Estimation!\n",
    "\n",
    "* `Prior` : What we already know about $D$. $\\large p(w)$\n",
    "* `Posterior` : What we want to know. $\\large p(w|D)$\n",
    "* `Likelihood` : The probabilistic distribution of what we want to know. $\\large p(D|w)$\n",
    "\n",
    "To calculate MLE,\n",
    "\n",
    "$$\\large \\text{likelihood} = p(D|w) = \\prod\\limits_{i=1}^n p(t_i|x_i) = \\prod\\limits_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(t_i-y(x_i|w))^2}{2\\sigma^2}}$$\n",
    "$$\\large \\text{log likelihood} = log(p(D|w)) = \\sum\\limits_{i=1}^n \\{ -log(\\sqrt{2\\pi}\\sigma) {-\\frac{(t_i-y(x_i|w))^2}{2\\sigma^2}} \\}$$\n",
    "$$\\large \\text{Since } \\sigma \\text{ and } \\pi \\text{ are constants,}$$\n",
    "$$\\large \\sum\\limits_{i=1}^n (t_i-y(x_i|w))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a385f9-59c6-4d3b-a0c8-16ef037f1123",
   "metadata": {},
   "source": [
    "## Maximum a Posterior\n",
    "\n",
    "While MLE maximizes likelihood, MAP (Maximum A Posterior) maximizes posterior.\n",
    "\n",
    "$$\\large P(w|D) = \\frac{p(D|w)p(w)}{p(D)} = \\frac{p(D|w)P(w)}{\\sum\\limits_{w}P(D|w)P(w)dw}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69c80d-124f-41ba-921c-227bc85d597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
